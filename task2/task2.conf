
task2config {
    # SPARK CONFIGURATION :
        spark.app.name="Task2App"

    # PIPELINE CONFIGURATION :
        prepareData=true
        trainModel=true
        predictOutliers=true
        removeOutliers=true
        computeTop10=true

    # MODEL CONFIGURATION :
        contamination=0.001
        maxSamples=256
        nbFeatures=1             # accepted values : 1 or 2
                                 # if 1 : only "speed" feature will is used
                                 # if 2 : "speed" and "trip_distance" features will be used

    # PATHS CONFIGURATION :
        tripsFilePath = "../data/yellow_tripdata_2019-09.csv"
        #tripsFilePath="../data/yellow_tripdata_2019-09_light.csv"

        suffix="c_"${task2config.contamination}"_f_"${task2config.nbFeatures}

        enrichedDFPath = "../data/enrichedDF_f_"${task2config.nbFeatures}".parquet"
        predictedDFPath = "../data/predictedDF_"${task2config.suffix}".parquet"
        cleanedDFPath = "../data/cleanedDF_"${task2config.suffix}".parquet"

        modelPath = "../models/iforest_contamination_"${task2config.suffix}".model"

    # AGGREGATION METHOD :
        aggregationMethod = "groupBy"       # accepted values : groupBy or reduceByKey
        nbPartitions      = 10              # tune depending on the cluster size (especially nb of available CPUs) and on Dataset caracteristics

    # LOG LEVELS :              accepted values : debug , info , warn , trace , off , error (set log level to "error" to avoid verbose logs)
        orgLogLevel = "error"
        comLogLevel = "error"   # tunes model (IsolationForest) log level

}
